---
layout: post
title:  智能有无捷径？
mathjax: false
comments: true
excerpt: "智能是否可以用'简单'算法实现"
date:   2015-01-27 11:31:12 +0800
categories: 人工智能
---

> 这是一篇关于 Michael A. Nielsen 的一本书的最后一篇文章的精心翻译（详见文末）。Nielsen 先生曾经写了关于量子计算和量子信息方面具有历史性的著作(*Quantum Computation and Quantum Information*)，在诸多领域（人工智能，数据挖掘，美学等等）有非凡的造诣。这篇文章凝聚了 Nielsen 的非常严谨的思维精神和高超的思辨能力，为此我花了很长时间将它翻译出来。如有不当之处请指正。



在本书中，我们聚焦了神经网络的方方面面:它们是如何工作的，以及如何将它们应用到模式识别中。它提供了很多非常实际的应用。但是，当然，我们对神经网络感兴趣的一个原因，希望有一天它的应用范围能够远远超出这类基本的模式识别问题。也许最终通过它们或者其他一些途径，能够在在数字计算机上实现相当或者超出人类智慧的思维机器。这方面的问题远远超出了这本书的范围，也超出了绝大多数人的预见能力，但是揣测这个问题未尝不是一件乐事。

关于计算机是否可以拥有和人类相媲美的智能一直饱受争议。我们现在不想纠缠于问题本身。尽管争论至今绵绵不绝，但是我相信智能计算机不是绝无可能的，尽管实现它可能复杂的超乎想象，以至于当今的科学技术无能为力。甚至部分反对者认为从物质角度无法完成（参见[vitalists](https://en.wikipedia.org/wiki/Vitalism)）。

然而，我们在这里探索的问题是：是否有一些简单的原理可以用来解释智能？更具体可行的是，*是否有简单的智能算法*？

真的有类似于 Hello World 那样简单的算法并不是个好主意（多几行 Hello world 显然不能真正增加智能），它听上去也太乐观了点。同时强烈的直觉告诉很多人：智能有不可归约的复杂性。这是因为他们有感于人类思维的光怪陆离，似乎一个简单的算法是难以胜任的。（然而）除却这些直觉，我觉得现在下结论为时过早。比如科学史就以生动活泼的例子教导我们：很多复杂的现象往往能够被简单有力的思想所描述。

以早期的天文学为例。上古时期的人类就已经知道天空是太阳，星星，月亮，流星和彗星等等的大杂烩。它们运动的方式千奇百怪：星星固执的向前走，彗星像个冒失鬼，日食月食搞不准什么时候就会出现。在16世纪人们认为试图找出统一规律的人一定是乐观成傻逼了。然而17世纪牛顿就给出了万有引力公式，不仅解释了这一切的运动，还解释和预言了潮汐效应和近地飞行这些东西。相比而言，十六世纪的那些被认为疯了的乐观者也只能算是可怜的保守党。

当然，科学上这种例子还有很多。想想看世界上难以估量的物质形态，居然能够被门捷列夫的一张元素周期表所描述，而这张表仅仅需要量子力学的几条规则就可以完全解释。大千世界形形色色的生物居然只是自然选择和进化的结果。太多太多的例子暗示了我们仅仅由大脑的复杂性，而轻易否定智能有着简单的原则，是不明智的。

  > 编者注： Through this appendix I assume that for a computer to be 
  > considered intelligent its capabilities must match or exceed human 
  > thinking ability. And so I'll regard the question "Is there a simple 
  > algorithm for intelligence?" as equivalent to "Is there a simple 
  > algorithm which can `think' along essentially the same lines as the 
  > human brain?" It's worth noting, however, that there may well be forms 
  > of intelligence that don't subsume human thought, but nonetheless go 
  > beyond it in interesting ways.


然而，乐观归乐观，智能有着复杂的根本机制，在逻辑上是可行的。万一我们大脑的多数机理是漫长的物种演化的结果呢（亦或是历史的巧合）？如果这种观点正确，智能就涉及到可观的不可归约的复杂性，没有简单的算法可以描述也在情理之中。

上述哪种观点是正确的呢？

为了深入考察，我们提出一个相关的问题：对于人脑如何工作我们是否有个简单的解释？特别的，我们来看看人脑复杂性的定量分析。首先一个视角来自于连接主义(参见[connectomics](http://en.wikipedia.org/wiki/Connectomics))。它关注大脑内部的连接特性：有多少神经元，有多少胶质细胞，细胞间有多少连接。你可能听说过这个数字-大脑有1000亿神经元，1000亿胶质细胞，神经元之间有100万亿个连接。这些数字令人震惊甚至害怕。如果我们想要通过理解全部的连接来理解大脑是如何工作的，我们显然不能得到一个简单的智能算法。

第二个观点更加乐观，它是从分子生物学角度看待大脑的。它研究需要多少基因来描述大脑的结构。为了把握这个问题，我们将对比人类和黑猩猩在基因上的差异。你可能听说过人类和黑猩猩的基因有98%的相似度。这个数字在主流调查结果中其实是有出入的，从95%到99%不等。存在差异的原因是，一开始人们仅仅比较了基因组抽样的一部分，而不是整个基因组。然而，在2007年整个黑猩猩的基因组都[测序](http://www.nature.com/nature/journal/v437/n7055/full/nature04072.html)完毕（参见[这里](http://genome.cshlp.org/content/15/12/1746.full)），现在我们大概知道人和大猩猩大约有1.25亿（总数约30亿）对基因不同。所以说我们和黑猩猩的基因有98%的相似度是不对的－严格来说事实上是96％。

1.25亿对基因能够存放多少信息呢？每对基因可以有4种可能性－即代表它们的基础物质有四种（鸟嘌呤 guanine，胸腺嘧啶 thymine，胞嘧啶 cytosine，腺嘧啶 adenine ）。所以只要2比特信息就足以确定一对基因。所以1.25亿对基因能够存放2.5亿比特信息。这就是人类和黑猩猩基因上的不同。

当然这2.5亿比特信息代表了人类和黑猩猩基因上的所有差异。我们只关心和大脑相关的那部分。遗憾的是目前没有人知道在整个基因差异中代表大脑差异的部分所占的比例有多大。但是我们暂且假定有一半的基因和大脑的差异有关，总共有1.25亿比特。

1.25亿比特感觉上是个很大的数字。让我们把它和人类周边的东西进行对比来感受一下它有多大。特别的，它等价于多少英文单词？假定一个英文字母有1比特信息－这好像太少了，毕竟字母表有26个字母－但是英语中的冗余量是很大的（每个字母出现的频率不同，并且由于单词的缘故，字母的出现不是随机的）。当然，你也可以争辩说基因中的冗余也非常大（启动子，终止子，结合位点，修饰段，隐式性状，免疫识别位点，无害突变，细胞的基础生理），所以每个两比特是过多的。但是我们应该忽略这些，因为最糟也就是我们过度估计了大脑的复杂度（～欲抑先扬者也）。在这些假定下，我们得到人类和黑猩猩基因上的信息差异大约等价于1.25亿比特个英文字母，或约250万个英语单词，大概是圣经的30倍。

这个看上去信息量很大，但是远非大到不可思议的程度，它还在正常人可以接受的范围内。也许一个人只是管中窥豹，但是一个团队或许可以正确理解它。这很复杂，但和大脑中1000亿神经元，1000亿胶质细胞，神经元之间有100万亿个连接相比是微不足道的。即使我们使用一个简单粗暴的方式来描述它们－比如10个浮点数来描述一个连接，这样我们也需要约7亿亿比特的信息。这样来说，对人脑基因层面的描述相比连接而言在数量级上只有原来10亿分之一的复杂度（而且总体来说可能我们远远高估了复杂性，也就是人脑应该更简单一些）。

由此我们得知基因不太可能包含一个对网络的完整描述，但是它必须确定大脑的大尺度结构和基本原理，这些结构和原理似乎足以确保我们人类思维成熟并且变得有智慧。当然，合理健康积极的环境和充足的营养也是发掘智力的重要条件。看起来，我们基因里面的信息包含了我们如何思考的基本要素。更重要的是隐藏在基因信息里的这些原理似乎是我们有能力全盘掌握的。

上面都是非常粗略的估计。有可能1.25亿比特是严重高估的结果，并且隐藏在人类思维之后的核心原理要紧凑的多。也许1.25亿比特中的大部分只是微不足道的改进。也许我们在计算中过度保守。但是很显然的是如果这是真的就再好不过了。对于我们目前的提议，关键点在于：大脑的结构非常复杂。但是还没有复杂到需要需要考虑其中每个连接的地步。从分子生物学的角度来看或许某一天我们人类理解大脑结构背后的基本原理。

（然而）在上面的几段中我忽略了这些基因差异只代表了人类和猩猩间的差异。我们大脑的所有功能并不是仅仅基于这一小部分基因。除却人类来说，猩猩本身也是卓越的思考者。也许智慧的秘密主要在精神能力上，这点猩猩和人类是有共通之处的。如果这是正确的，人类大脑只是猩猩的一个小版本改进，而底层的原理的复杂度相差无几。放下传统的人类至上主义，这种观点不至于难以置信：人类和猩猩的基因分离仅仅有[500万年](http://en.wikipedia.org/wiki/Chimpanzee-human_last_common_ancestor)的历史，而500万年仅仅是进化历程的冰山一角。然而在更加有说服力的论据出来之前，我仍然认为人的独特性和那1.25亿对基因关系更大，而不是主要存在于其他基因中。（并且，如果和智能相关的基因早就完备了，那么从进化论的角度来说，这种极具优势的变异会让智能生物很早就出现并且霸占全球，而不是像人类一样这么晚才登上进化史舞台。事实上智能有爆炸式的威力，人类一出现就给整个地球带来了难以想象的变化，特别是科学技术出现后，仅仅数百年的时间而已）

采取分子生物学的方法对待大脑，已经给大脑的复杂度带来了9个数量级的削减。在感到兴奋的同时，它还是没有告诉我们是否可能存在一种真正简单的算法可以产生智能。我们可以进一步削减复杂度吗？更切题的是，解决“是否可能存在一种真正简单的算法可以产生智能”这个问题是否可能？

遗憾的是，对于这个问题我们没有充足的证据。（虽然如此），还是让我介绍一下一些现已存在的证据。这里我需要指出一点，这些观点可能没有那么充分，只是代表了最新的工作进展，而不是一份彻底而完整的调查（那是科技史应该做的）。

2005年5月《Nature》的一篇[实验报道](http://www.nature.com/nature/journal/v404/n6780/abs/404841a0.html)暗示了可能智能有一个简单的算法。Mriganka Sur 领导的实验团队修改了新生雪貂（常用于神经生理学研究）的神经连接。通常来自眼睛的信息会被传入所谓视觉皮层。但是这些雪貂的视觉神经被科学家们重新定向到了听觉皮层，即大脑中通常用来处理听觉的地方。

为了理解他们做实验的时候发生了什么，我们首先需要了解一些有关视觉皮层的东西。视觉皮层中有很多定向栅(?)（[orientation column](http://en.wikipedia.org/wiki/Orientation_column)）。它们是由小片细胞构成的，每个只对特定方向的视觉刺激敏感。你可以把它们看作迷你方向传感器：当光线从特定方向照过来时，相应的一部分细胞便会活跃。当光线被移动时，另一部分细胞会活跃。视觉皮层最重要的高级结构之一是定向层（[orientation map](http://www.scholarpedia.org/article/Visual_map#Orientation_Maps)），它勾勒了定向栅如何排布。

科学家发现的是，当视觉信号被重定向到听觉层后，听觉皮层发生了变化：定向栅和定向层开始浮现出来。它相比通常视觉皮层中的更加无序一些，但是有无可争辩的相似性。更近一步，科学家简单地测试了它们如何应对视觉刺激，训练它们对不同方向光的反映。这些测试暗示雪豹仍然可以借助听觉皮层学会去“看”，至少是发挥了基础的功能。

这是个令人吃惊的结果。它揭示了不同脑区用相同的原理对感官数据进行处理。这种同一性为智能有简单的原理提供了或多或少的支持。然而，我们不应该自欺欺人地说在这个实验中雪貂的视力能有多好（显然视力和听力或多或少都有损失）。行为测试仅仅反映了非常粗略的视觉层面。而且，我们没有办法咨询这些雪貂它们到底是不是“学会看”的。所以这个实验不能证明听觉皮层可以给雪貂高质量的视觉效果。所以它们仅仅为智能有简单的原理提供了有限的证据。

有什么证据与智能有简单的算法相抵呢？一些证据来自于进化心理学和神经解剖学。自1960年代以来，进化心理学家发现了大量的人类通性，一些复杂的举动是人类共有的，无论文化和教育。这些人类通性包括亲子之间的乱伦禁忌，音乐和舞蹈的使用，以及更加复杂的语言结构，比如咒骂，禁忌语，代词甚至是基本的动词。一堆神经解剖学的研究表明，人的很多行为是受大脑特定区控制的，这些区域的划分是人与人之间类似的，这可以给上述现象带来解释。综上，这些研究暗示了很多特殊的行为被硬编码在了我们大脑的特定区域之中。

有人从这些结果中总结出，大脑不同的功能肯定要有不同的解释，结果就是大脑功能有着不可约化的复杂性，复杂到解释大脑的运作（比如一个简单的算法）是不可能的。举例而言，著名人工智能研究者 Marvin Minsky 就有这种观点。上世纪七八十年代他发展了自己的“社会思维”理论，其基础思想是人类智慧是众生芸芸的大社会的某种计算过程，他称这个过程为“代理”（agents）。[在他描述这个理论的书中](https://en.wikipedia.org/wiki/Society_of_Mind)，Minsky 总结了他认为的有力观点：

  > 是什么魔术般的技巧让我们智能? 技巧就是根本没有技巧。 
  > 智慧的力量是我们的多样性凝聚成的，而不是来自于单个完美的理论。（其实这是另外一种人择原理）
  > 为了回应对他的书的评论*，Minsky 细化了《Society of Mind》的动机，提出了一个类似于上文的基于进化心理学和神经解剖学的论据：

  * In "Contemplating Minds: A Forum for Artificial Intelligence", edited by William J. Clancey, Stephen W. Smoliar, and Mark Stefik (MIT Press, 1994).

  > 我们如今知道大脑本身是由上百个不同的区域和核心构成的，每个都有非常不同的基础架构和排布方式，并且很多明显设及精神活动的不同层面。当今大量的知识表明，很多传统的现象例如“智慧”和“理解”事实上涉及了复杂的机构。

Minsky 显然不是仅有的持此观点的人。我仅仅将他作为这类观点的支持者的一个例子。我觉得这些论据引人注目，但不相信它是压倒性的。虽然大脑是由不同的区域构成的，有着各自不同的功能，但是得出大脑没有简单的解释不是顺理成章的。也许大脑有不同的结构也是基于某种潜在的共同原则，这和行星彗星运动皆服从一个万有引力理论类似。（不简单很可能只是某种不完美，也无需完美。牛顿定律存在与太阳系行星轨道不是正圆并不矛盾）Minsky 和其他任何人都没有给出足够令人信服的论证。 

我的第一感觉是支持智能有简单的算法。主要的原因是我喜欢这个想法，超越一切的是它是个令人乐观的主意。在研究领域无端的乐观通常比现实的悲观有更多产出，因为乐观者有勇气扬帆起航，尝试新的东西。这是发现之路，甚至往往事与愿违。悲观者从狭义角度来说更“正确”，但是发现所得会相比乐观者更少。

这种视角和我们通常甄别观点的方式有天壤之别：通常我们只是试图搞明白孰对孰错。那是我们对待每天实验的细枝末节的方法。但是它可能在判断一个大胆的想法上面出错，这些想法定格了整个研究程序。有时候， 一个主意对错与否尚未明朗。我们可以拒绝轻易相信这些想法，转而将所有的时间都花在寻找蛛丝马迹上，尝试分辨出哪些是真的。或者我们可以坦然接受无人知晓的现实，转而花功夫钻研发展大胆的想法，因为我们明白不能打保票成功时，只有我们的看法上有先进落后之分。

终上所述，即使在最乐观的情形下，我也不相信智能会有那么简单的算法。举个实例，我不相信我们可以找到一个确实很短的Python/C/Lisp或其他什么语言的程序，只要数千行代码就能达到智能的程度。我也不相信我们会找到一个真的易于描述的神经网络可以实现人工智能。但是我相信这是值得尝试的，就好像我们可以找到这样一个东西一样。这是探索的途径，说不定在这条路上某天我们真的能够写一个长一点的程序或者建立了一个稍复杂的神经网络，确实体现出了智能 。试图探索一个非常简单的算法是否可能存在也是有意义的。

十九世纪八十年代，声名显赫的数学家和计算机学家[Jack Schwartz](http://en.wikipedia.org/wiki/Jacob_T._Schwartz)被邀请到了一个关于人工智能的支持者和反对者的辩论中。辩论变得有些失控（人类历史上争议最大的问题之一），支持者过分强调令人激动的东西就要到来了，而反对者也加强了防抗，声称人工智能是理所当然不可能的。Schwart是一个旁观者，在辩论白热化的阶段依然一言不发。在中场休息时，他被要求陈述自己的的看法。他说：“好吧。有些东西或许还有一百块诺贝尔奖之遥”（这个话更加准确的内涵是“很多东西值一百块诺贝尔奖，同时也要等一百块诺贝尔奖到齐了那么长的时间”。[参见第22页](http://books.google.ca/books?id=nFvY20pHghAC)）。这对我来说是个极好的回应。人工智能的关键时简单有力的思想，我们能够也应该积极地探索这些想法。但是我们需要很多这种想法，并且我们还有很长地一段路要走。

［本篇完］

> 无论如何，你看完了，或许只是一扫而过。但是我想说一个发现：这本书（*Neural Networks and Deep Learning*）的确有人翻译过，但是漏掉了关键的几章（一个是本篇，一个是严格的数学推导），以及书中的大多数思考题，因为它们作为技术来说“没用”、“浪费时间”。但是，我想说的是，正如“钱学森之问”所暗示的，中国教育确乎有一些难以遮掩的失败之处（产生不了大师，留不住大师）。我们是不是放弃了一些真正需要人来思考的东西？随着很多技术的日渐成熟和套路化，与其说大家只关心技术（况且很多真正的“技术”还在别人手里），不如说大家希望偷懒，希望工作等等一切非常稳定。然后，说实话，我看到了很多机器的影子。也许迦南道雄所认为的“日后人们越来越像机器，而机器越来越像人”是正确的，也是我们看到的事实。那么在不是很遥远的将来，不愿思考的人们又会过着怎样的生活呢？

---

This is an 'open-sourced' page created by Si-Yuan Zhuang. For reference, plz attach this page block to your blog, thanx.

This page is a translation & comment version of Michael A. Nielsen, [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com), Determination Press, 2015 with Creative Commons Licence. I am grateful to the original author.

This work is licensed under a [Creative Commons Attribution-NonCommercial 3.0 Unported License](http://creativecommons.org/licenses/by-nc/3.0/).

![Creative Commons Licence](https://i.creativecommons.org/l/by-nc/3.0/88x31.png)

