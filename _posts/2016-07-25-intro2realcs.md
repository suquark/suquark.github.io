---
layout: post
title:  入门－真实的 Computer Science & Technology
mathjax: true
comments: true
excerpt: "入门－真实的 Computer Science & Technology"
date:   2016-07-25 +1828
categories: lecture
---

(未完待续)

这个是给CS方面新人深度科普用的

首先本人看上去就很弱，欢迎大家调教（咦？）

－－－正文－－－

很不幸的是，计算机是一个极其大，内容极其多的学科。如果之前你以为就是写写代码或者设计电路那就错了。	

计算机主要问题是计算，“计算”wikipedia定义是对信息的处理，所以计算机工业也往往叫IT（信息技术）


## 计算机的来源

### 能造出这样一种机器的理由

能够有一种模型，只要人们能够明确表述出某种计算或者操作的具体规则，它就模仿人做到相同的事情？这个一点都不显然。

图灵构造性证明了：可以。这种模型叫`图灵机`。实现图灵机同等功能的机器叫`计算机`。

这种操作或者具体规则叫`算法`。

### 从逻辑到硬件

图灵机是符号逻辑，算法是人们的思维逻辑，真实的硬件理解的是二进制编码的逻辑（电路啊电路啊不这么做电路哭死啊）

人们很快填充了算法和硬件两者之间的东西。由此创造出了计算机这个专业以及它的专业词汇。

- 算法所依赖的数据关系叫数据结构。描述算法的逻辑形式叫程序。设计程序的入门课程叫程序设计。

- 程序的内容叫代码，写代码的行为叫编程，（专业）写代码的人叫程序员，代码的具体规则叫（计算机）语言。

- 把代码（逻辑上的程序）变成计算机硬件可以识别的程序的过程叫`编译`。执行这个过程的程序叫编译器。（C，C++，Fortran，Pascal等语言大多依赖编译器）

- 计算机硬件可以识别的程序往往又叫做`二进制程序`（因为此时的代码是二进制形式），相应的编译前的（逻辑层次的）的代码叫特指为`源代码`。

- 能够直接读取源代码并执行其功能的程序叫`解释器`，它（just-in-time模式的例外）不需要编译。（python, lua, bash, perl, php, javascript等语言大多依赖解释器），由于没有对应的二进制程序，它们的源代码又往往称为`脚本`。这种语言也称为`脚本语言`

- 管理和协调程序的程序集合叫`操作系统`（也可以视为软件／硬件中间的逻辑层次，因为有了操作系统后其他程序基本不用直接关心硬件（用于特定硬件的驱动程序除外））

- 模拟真实计算机硬件的软件叫`虚拟机（软件）`

操作系统的出现大大增加了计算机词汇。这里不一一列举了。


### 计算机文化

- 精通计算机原理和软件缺陷的家伙叫`黑客`。利用缺陷进行破坏的叫`骇客`（两词有时候被混用）

- 第一个异常有名的用于编写程序的软件叫`Emacs`，它被人加入越来越多的功能，有人甚至用它控制煮咖啡(真有一个煮咖啡标准协议的)。后面出现一个同样有名的叫`Vi`，它的改进版叫`ViM`。它们各自的用户经常互相指责对方（最好的编辑器）［误

- 不给用户展示源代码的应用叫`闭源应用`，相关的行为叫`闭源`。反之叫`开源`。

- 比较早的应用很广的操作系统源于Unix（包括现在苹果的操作系统的来源）。后来微软自立门户搞了Windows。它们大多都是闭源的。之后Linus对Unix不满开发了Linux（这个名称是编辑取的，不是本人。另外狭义的Linux只包括Linux内核）。Linux系统的不同版本系列叫`发行版`，Android就是其中之一。Linux的出现很大程度改变了服务器和嵌入式设备的生态。

- 用于通用计算的单元叫`CPU`，图形计算的叫`GPU`。Nvidia和AMD的GPU被各自称为N卡和A卡（至于和核弹关系自己搜去）。

- C语言出来之前不少操作系统使用Pascal语言编写。

- Lisp原意是为了人工智能，现在恐怕用的最多的情形之一是给Emacs写插件

- Java是比较早的试图应用于网络应用的语言，当时Netscape觉得Java名气大就命名浏览器中的脚本语言叫Javascript（两者没有什么关系）并且这个语言10天就被设计好了。现在这两个语言都很火，也都列在被吐槽的前几位。

- Intel 奔腾系列的某个芯片由于打表打错了造成了运算错误。这可能是最严重的芯片设计错误之一。

- PHP被你们玩坏了

- Python是Guido在圣诞节觉得无聊写出来的

- 待补充

## 计算机的支撑体系

支撑体系让计算机成了能够实用的东西。

计算就要算的快，算得好，算得准。

由于历史的原因，计算机支撑体系大致分为软件和硬件。硬件的任务是提供基本的操作和计算能力，软件的任务是组织和利用这些计算能力解决实际问题。

### 算的快

如何算的快？

- 硬件要好。一个很烂的硬件很难发挥性能。硬件方面存在诸多矛盾，比如越专用的硬件越快，应用范围越窄，价格越高；越通用的硬件就相反，所以不能指望硬件一劳永逸，它永远是要发展的。此外硬件的灵活性一直是个问题（毕竟造出来就定型了，但是近年来FPGA等在改变这个情况）。于是衍生了芯片工艺、体系结构、硬件层次、用于设计硬件的编程（HDL）、并行（不同粒度，从指令到任务到整台机器）等诸多问题。
- 软件要适应硬件，充分发挥硬件性能，由此有了并行、并发、同步、异步这些控制软件执行的方式，这样才能充分利用硬件。由此衍生了同步控制（原子锁、互斥量等等）、并行编程（针对不同的硬件，CPU，GPU等等）、（并行）软件验证（如何保证和证明一个并行的程序按照自己的想法运行？出错了如何分析？）、包括异步／回调处理各种请求的各种方式（当今的很多能承受高负载的网络框架，用户体验好的前端）等等。
- 软件能够用巧妙的方法较快的解决问题。这个就是算法，而且一般是指普适性的算法（具体问题的算法差异和这个很大）。但是算法本身也不简单，比如如何设计一个算法？如何分析具体算法能有多快？如果算法有随机性，那么平均如何？某个问题最快的随机算法平均是否会快于确定的算法？是否所有的随机都可以用伪随机数模拟？针对某个问题，能设计出的最快的算法能有多快？或者是否存在比某个算法更快的算法？某些算法是否可以很容易的互相转换，从而可以视作一类？某个问题能够设计出的最好的算法按照计算难度可以分成哪些类，这些类之间的关系是什么？如果需要并行，算法又该如何设计？如果是量子计算机，又该如何设计更加高效的算法？这些问题的答案都不是很平庸和明显的。
- 计算任务需要合理管理，于是有了操作系统。这方面又有很多很多问题需要解决。比如如何分配和调节各个“任务”（进程）的资源？如何调度它们的工作顺序和时间（优先级／紧迫性／实时性／交互性）？如何保证系统的容错性和计算结果的一致性（比如突然断电了如何保证恢复时可以知道断电前哪些东西其实没有完成这样可以重置它们以免造成更多的错误）？如何保证系统的安全性？如何控制系统中的各种权限？如何管理用户，用户权限和密码？如何让操作系统跑在不同的硬件平台上（不是每个不同型号的笔记本都要重新设计一个操作系统）？如何识别管理外部硬件（想想有多少种型号的U盘，移动硬盘，显示器，投影仪，蓝牙，Wi-Fi，网线，光盘驱动器，键盘，鼠标，有线的和无线的，打印机，集成显卡，独立显卡，电源管理，音响耳机）？如何和外部计算机互联／共享，网络通信？系统太复杂之后又出现了代表核心逻辑的“内核”，内核本身的结构也是受到高度重视的。
- 。。。

以上各个问题都形成各个方向。

### 算的好

(好吧今天有事明天再说)


