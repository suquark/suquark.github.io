---
layout: post
title:  智能是否可以用算法实现？
mathjax: false
comments: true
excerpt: "智能是否可以用算法实现？"
date:   2016-02-10 16:07:39 +0800
categories: 人工智能
---

> 本篇讨论人工智能的算法性质，以及一些更深刻的问题。我们在此处只讨论可行性。关于算法本身到底需要多复杂，参见[智能有无捷径](http://suquark.github.io/人工智能/2015/01/27/智能有无捷径.html)。

智能是否可以用算法实现？这个问题由来已久。
罗杰特在《皇帝新脑》中曾经论述过这个问题。他的观点是不可能。

但是，在将近20年后，特别是 deep learning 这个领域进入人们视野之后，很多变化都超出了人们的预期：机器不仅能够识别图像，还能“看图说话”。在去年，微软在 ImageNet 上利用深度残差网络第一次让机器对非特定图像的识别率超过人类。今年初，Google 的 AlphaGo 程序利用价值网络和策略网络等技术非常轻松的打败了欧洲围棋冠军，比人们所预想的至少提前了10年。

种种突破预示着一点：曾经我们的观点一定是哪里出现了问题。让我们回顾一下那些典型的反对人工智能的意见，看看它们有什么问题：

## 中文房间悖论

参见 [中文房间悖论](https://en.wikipedia.org/wiki/Chinese_room)

![Chinese Room](/static/2016-02-10-ChineseRoom.jpg)

一个人在房间内，他完全不懂中文，但是周围有足够的资料可以查阅。外面的人用中文和他说话，他通过查字典来回答。外面的人会认为里面的人精通中文，但是实际上他对中文一无所知。

这个悖论攻击的是：算法不可能像人一样“有意识”，所以是一种伪智能。

但是，我们再考虑一下，会发现一个问题：如果要求一个房间流利的说中文，并且质量非常高，需要多少人同时查阅？也许要很多，是吧？比如有的人要查修辞，有的要搞成语，有的要对账，有的要查中文幽默，有的要对付流行语，等等等等。并且还要考虑到合作，就要求所有的人互相沟通，还要人做中继，并且为了克服人多带来的内耗，可能最终需要像印度这个国家这么多的人。

这时候，每个人的确还是不懂中文。但是，如果把每个人当作神经元，那么这个房间，就好似一个大脑：单个神经元显然不懂我们在干什么，它们只管按照突触间结合规律互相传递电信号，并且数量极其多。但是这个整体，是具有意识的。

这个悖论的根源在于将房间中的人和房间中的东西强制分离开了。实际上，这个房间确实有理解中文的属性，但是单独的人和单独的字典都没有。我们和一个人交谈的时候，如果这个人无论如何确实很高妙，我们必须承认他有智慧。一个算法的局部可能并没有智能，但是它确实足以表现出智能的一些特性。

## 超越自我的悖论

这个悖论的理由很简单：人如果能够创造超过自己的智能是不可能的，能设计超过自己思维能力的东西，似乎违背了客观性。

这个悖论可以用这样一个思想试验打败：
现在，我要让一个人相信我造出了一台比他聪明的机器。我让他和机器做任意他想要的对决，作诗啊什么什么只要允许都可以，结果基本上都是他输，所以到最后不得不承认这个机器比他厉害。但是我怎么做到的呢？我在这个机器后面放了1000个人。1000人对付一个人当然绰绰有余。

这种测试方法类似于所谓的[图灵测试](https://en.wikipedia.org/wiki/Turing_test)。

![Turing's Test](/static/2016-02-10-Turing-Test.png)

其实，一个人能不能做出一个比人聪明的机器很让人怀疑，但是1000个人说不定就可以。并且造出来之后，智力是允许叠加的（虽然效果可能远没有没有累加那么好），我们像繁衍出更多的人一样，造出更多的机器，提高机器整体的智力。这是在空间上的超越。

并且由于人类智慧的历史累积效应，现代人的智慧很可能远远超过古代人－－毕竟我们比他们知道的多得多。我们可以在千里之外聊天，造出计算机这些东西，也可以把人送上月球，但是古代人很难想象这些东西。这是在时间上的超越。

## 智力悖论

这个悖论对机器学习提出了怀疑，它指出学习不会提高智力，所以机器很难达到人的水平。从某些智力测试标准来看，古人的智力和我们似乎差不多，没有特别大的变化。智力是人们固定的属性，不能够通过学习改善。

首先，不同年龄段的人的智力是有区别的，所以智力测试是按照年龄段的相对标准。幼儿园和小学的孩子很难理解“无穷大”，都是1，2，3，4...这样往上数，数到100就觉得好大。并且很多孩子天真的想弄明白什么数最大，这时候有人会说无穷大，但是孩子并不明白到底无穷大是什么。直到有一天，孩子会不知不觉地明白：数是无限多的！他再也不需要一个一个往上数了。

这说明，一个人的智力也不是不变的，而是会发展的。并且有个有趣的现象：经常做智力测试题的人他智力测试的结果会变好－－当然会变好，这个很像学习对吧？可以想象一个人生来就专门做各种智力测试，他测得的智商很可能会爆表（什么智力测试题？我一眼能看穿！）但是他的生活中的实际表现的智力一定很差－－他不会说话，也不会做试验，也不会照顾自己的生活，由于没有背加法表，做加法都要搬指头。他只是熟练地应答那些智力测试题而已。

这给我们的启示是，我们应该全面评价一个人的智力。智力测试标准只是一种方便的标准罢了。并且我们这里更关心的是智慧－－它比智力要丰富的多，包括一个人的智商，情商，态度，甚至怎样去哄女(男)友开心，这些背后的过程恐怕都不是很容易。一般性的学习确实有可能不能提高智力，但是一定能够提高智慧。并且智慧更像是评价智能的标准，因为它要苛刻的多，并且标准不随年龄变化：我们经常会夸一个小孩聪明，智商高，但是对于说他有智慧恐怕是很慎重的，对吧？（一个智慧的小学生？？？）

如果你到两个星球参观，第一个整天拜天拜地，每年还杀自己的同类祭祀。第二个已经能够发射火箭，甚至走出自己的星系。你会觉得哪个有可能有智慧一点呢？实际上，前面一个恰恰是我们的祖先，而我们继承他们的知识，变得更有智慧。

## 特征学习悖论

人工智能直到现在仍然以各种各样的形式依赖于特征：特征是某些特有的一类东西，它用来给东西分类。比如黄色的（有的偏绿），并且像镰刀一样弯的，表面可能还有一点黑点的是香蕉。deep learning 技术是自动获取了特征，但是本质上还是特征。

有人对特征深表怀疑：不，人类本质上是意识并且理解它，不是靠特征来区分东西的。
真的如此？请看下图：

![倒着的女人的脸](/static/2016-02-10-Face.jpg)

很正常？你倒过来看看！

哦？相信大多数人还是有点吃惊的。我们为什么会有这样的错觉？答案是这根本不是错觉，而是我们本来就是如此。比如说似乎没有人们教我们这些符号“ ^\_^ ,  -\_- , T\_T  ,  : )  , : ( ” 是什么意思，但是我们大多数人都明白，为什么？因为这和人脸有一样的特征！我们会犯错，是因为我们会把人眉毛上扬，嘴角上弯当作愉悦或者微笑的特征，而反过来是生气和不愉快（甚至不考虑眼睛和嘴的相对位置！）。我们把图给倒过来的时候下弯变成了上扬，所以我们直觉上感觉不出来，直到我们把图倒过来。但是我们为什么直觉上不是很在乎眼镜和嘴的位置？－－生活中和你倒着聊天的有几个？所以生物需要关心吗？


此类错觉还有很多，很多都是人类识别特征的铁证。

比如直觉上你觉得“\] \[\] \[\] \[\] \[ ”该怎么理解（被字体坑了别说我不对！！！）？几个像框一样的东西对吧？但是你为什么不这么理解："\]\[ , \]\[ , \]\[ , ]["？因为原来那样简单？但是什么叫“简单”？实际上，你看到的方框是一种特征。生活中像方框的东西太多了：插座，黑板，手机，电视，遥控器，桌子，窗户，而"][" 这种东西相比要少一些。为什么人们倾向于用方块？因为方块是一种非常良好的分块特征，分块会让处理东西变的简单有序（比如很适合排版文字，排按钮，或者在里面嵌入东西），所以你倾向于这样做。


## 决定性悖论

一直以来，决定性悖论对人工智能的冲击甚为严重：算法几乎都是决定性的，就算是随机数，很多人都知道是伪随机，也就是还是决定性的。现代人工智能对这个提出了有力的回应。

真随机似乎只有量子力学里面有，所以一度人们怀疑人脑是不是必须是量子效应的。但是这个带来的问题和麻烦非常严重，以至于现在很少有人非常坚信这一点：首先，在人脑的温度（这个温度吓哭了做超导和离子阱以及冷原子的物理学家，主要是他们做量子计算）和溶剂环境（这种复杂高噪声环境吓哭了多数化学家）下面，宏观（细胞尺度）的量子效应的作用时间都不到百亿亿分之1fs，这么短的时间都不够光穿过一个细胞核。大脑尺度的量子效应低到已经不值得估计。只有分子反应的尺度（原子级别），量子效应才存在(电子可以到fs量级，核磁可以再长一些)，但是这时是必须的，也是所有物质都有的。

并且量子效应带来了诸多复杂问题，比如一致性问题：人和老鼠神经元结构类似，如果量子效应是关键所在，为何老鼠没有表现出过多的智能？从这里看反倒是神经元的累积效应更占优势。同时智能如果非常依赖于量子效应，还会带来更加难以解释的自主意识问题：比如我观察你的时候，你的波函数会坍缩，诸如此类的问题这里就不多说了。

但是人们沉醉于研究决定性问题的时候，却往往忽略了一个问题：复杂性问题。
如果我告诉你 *一个确定性程序得到了一些我们几乎看不懂的东西* 你信不信？

不要惊讶，下面就是一个例子，这是一个程序学习的结果，是一个[由24*24灰度图像得到单个数字的函数的元数据（实际上是一个DNN）](/static/2016-02-10-Training-Result.html)
我们看到了一大堆数字，恰如看到了一大堆神经元那样茫然无助。

*注：这个程序有一定的随机性（伪随机），但是是可以去掉的，因为主要是为了预处理数据。这点我们自己就经常做，比如我们拿到一个新的东西的时候会好奇地随便翻翻它，以看到它全部的样子，这样一定程度上可以有更好的了解。近似随机的翻动是为了避免“绕地球100圈然后认为地球是个圆柱”这种错误，从而提高泛化能力。*

实际上最新的一些算法得到的结果可能是1GB左右的数据，这个绝大多数人一生都看不完，更别说理解它。

我不想描述算法是怎样的（篇幅不够说明白），但是我保证它的主体部分不超过20行，细节部分不超过1000行。

### 一个确定而简短的程序怎么可能得到我们不理解的结果？ 

首先，过程中没有随机，也没有混沌，运算精确无误。但是为什么最终得到了一个看似随机的东西？原因是，这些随机的东西来自于训练数据。

这点并不难以置信。我们学会分辨东西后，变的不是东西，而是我们的大脑。我们的绝大多数知识来自后天学习，无论是有意的还是无意的学习。

这里有个动画 (from Mr. Christopher Olah) 表述了如何通过逐级变换（类似大脑中的神经元。同时这个过程是高度并行的），区分两个纠缠的曲线：

![螺旋线](/static/2016-02-10-spiral1.gif)

由此我们可以得到一个很奇怪的结论（但是确实如此）：

> 我们正是通过扭曲自己得到对世界的认识

但是还是有人心存怀疑：我们学到的信息到底是什么？真的是好似之前所示的一堆数字一样的我们难以理解的东西？

> 学习实质上是一种编码的过程

事实可能真的如此。学习实质上是一种编码的过程，编码的原理可能并不复杂，但是得到的东西确实是我们自己难以"理解"的，但是它实实在在是有效果。比如我现在要大家精确的画出自己学校的校徽，或者自己公司的标志，除了过于简单的那些，恐怕绝大多数人不能很确信的画出来。但是，大家绝对看到它能够认出来！动物也是一样的反应。

### 自我意识 ？

在上面一段最后我们说到动物似乎有和我们类似的视觉效果，这个恐怕很难否认。并且，绝大多数动物的视觉能力要远远超过我们：比如老鹰能够在近千米的高空观察地面上面的小动物。人的大多数感官都已经退化了，同时带来的后果是相应的大脑区域，比如视觉区听觉区，似乎没有很多动物强。

但是，有多少动物能画自己看到的东西比人好呢？－－等等，问题似乎是有多少动物能够画出印象中的东西？有些报道指出有某个动物会画画，但是画的更像是“艺术画”，也就是其实它并不能准确的表达出它所想的东西。

但是人却非常不同：人可以通过绘画、音乐、文字、肢体语言、表情眼神、语言还有大量的我们称为修辞的方式（文学和生活中都有的方式）：比喻、拟人、夸张、重复、反问、幽默、故作正经、起哄（以及高冷，卖萌，装逼，扯淡？？？）等等，来尽力表达自己的意思，虽然不是全部。同时人们也有了对应的理解它的能力，虽然同样不能完全复原表述。

我们描述的很像，但是不能完全还原原来的东西。这是人们表述的特点。正如这篇博客，我只能尽力而为，剩下的要读者去思考。（这里修正一个误区：比如我看到一个筷子后，回去学做了一个筷子，这个算不算“完全表述”？我觉得不是的，这是因为你做的是能用的那个筷子，而不是一样的筷子。）

> 我们描述的很像，但是不能完全还原原来的东西（损失或多或少）

将精确表述出来一些东西的作为根本原理，曾经是人工智能的重大失误。比如很早之前人们想用数理逻辑和简单的概率来制造智能体，因为人们认为公理和逻辑才是最基本的。但是逻辑就其本身而言是个非常精准的抽象表述而已，我们可以从它得到很多精密的东西，但是它并不根本，并且带来了诸如决定性、自主性、公理完备性等等非常严重的问题。

> 通过表述来传递信息是有损失的，但是表述出的东西却可以无损传递

然而，非常幸运的是，我们表述出来的很多东西是可以通过外部手段来无损传输的。但是这个可能真的是个巧合，伟大的巧合。人们开始画画时没有预想到有照相机，开始写字的时候没有预想到有纸和复印机，开始唱歌或者演讲时没有想到有录音机和录像，开始装逼时没有想到有“截屏和右键保存”。直到现在的计算机和网络把一切发挥到了极致：都是二进制信息而已（所以某些人“发车”也比古代方便了，嗯嗯）。现在我的这个blog也有赖于这一切才让你看到。

> 表述在底层机制上非常像给自己“解码”

表述，和记忆一张图片相比，更像是一种“解码”过程。我们描述东西不需要什么实体，只需要我们的大脑－－我们和动物相比，以非常高超和精准的手段将“自己”表述出来，这个非常像“解码自己”。同时，我们能够理解自己和别人对自己的解码，理解和体会的过程更像记忆和“编码”，这样就可以做到“反思自己”，比如思考自己为什么存在？意义在哪里？我是谁？并且纠正“自己的错误”，或者指出“别人的错误”。从这里我们看到了：

> 自我意识

当然这里我给一个猜想，如果一个东西：
1. 能够适应环境，从而独立存活。
2. 能够有非常强的表述和理解能力

那么它很可能就有自我意识。

### 我们本身非精确的表述会成为我们本身智能的障碍吗？

不像是。这种例子非常多。比如测量，一般都有难以消除的误差，但是不影响很多非常精确的预言。你摇一摇头会觉得头晕－－这肯定给你的神经系统带来了一些影响，但是并没有显著改变你的记忆和意识。

## 图灵完全悖论

很多人知道通用计算机是图灵完全的。也就是原则上它可以模拟人的任何行为。但是为什么计算机，特别是在以前，难以表现出智能的特性？

### 完全不等于容易

原因是，完全不代表容易。一个抽象的例子是：用试除法来判断一些数是不是素数。对于某个数N，你可以除2, 3, 4, ... N-1，这样当然可以得出结论。但是，如果你稍有一点数学基础，就会知道除2, 3, 4 ... round(sqrt(N)) 就够了，因为乘法是可交换的。当N到1亿亿这么大的时候，如果恰好遇到很多素数，你就会比别人快1亿倍！

更加极端的例子出现在下围棋上。下围棋的搜索空间之大超乎想象，所以不像国际象棋那么好对付。但是如果你找到“一些方式”，就能大幅提高速度，和Google的AlphaGo一样。围棋能够下的原因是，它是有某些复杂的规律的，但是恰如一张图一样，你说不出所以然，你可以出一本下围棋的书，但是不能保证所有人看了都下的很好（表述和理解的损失）；但是，就如看到一张图你能认出来一样，高手下围棋就能“有感觉”，不同的是一个是先天具有的能力（视力），另外一个是后期对棋盘的感觉。



---

This is an 'open-sourced' page created by Si-Yuan Zhuang. For reference, plz attach this page block to your blog, thanx.

Some pictures are picked from the Internet. If the origin author would like to claim its authority, plz contact me.

This work is licensed under a [Creative Commons Attribution-NonCommercial 3.0 Unported License](http://creativecommons.org/licenses/by-nc/3.0/).

![Creative Commons Licence](https://i.creativecommons.org/l/by-nc/3.0/88x31.png)

